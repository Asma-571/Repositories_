{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Alshehri_Asma_HW4</h1></center>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Asma Alshehri\n",
    "<br>\n",
    "Github Username: Asma-571\n",
    "<br>\n",
    "USC ID: 5168462498"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Time Series Classification Part 1: Feature Creation/Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Download Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install bootstrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import glob\n",
    "import csv\n",
    "from scipy.stats import trim_mean\n",
    "import shutil\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from bootstrapped import bootstrap as bs\n",
    "from bootstrapped import stats_functions as bs_stats\n",
    "import shutil\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the AReM Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the AReM data from: https://archive.ics.uci.edu/ml/datasets/\n",
    "Activity+Recognition+system+based+on+Multisensor+data+fusion+\\%28AReM\\\n",
    "%29 . The dataset contains 7 folders that represent seven types of activities. In\n",
    "each folder, there are multiple files each of which represents an instant of a human\n",
    "performing an activity.1 Each file containis 6 time series collected from activities\n",
    "of the same person, which are called avg rss12, var rss12, avg rss13, var rss13,\n",
    "vg rss23, and ar rss23. There are 88 instances in the dataset, each of which contains 6 time series and each time series has 480 consecutive values.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before splitting the data to train and test, In every csv file in AReM I will check for any missing or null values, any rows that contain more or fewer values than expected, which effectively skips over rows with extra commas. Finally checking if a dataset has 480 rows and 7 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time index #Columns: time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset4.csv in ./AReM/bending2/ contains missing or null values\n",
      "dataset14.csv in ./AReM/cycling/ has an error: Error tokenizing data. C error: Expected 7 fields in line 485, saw 8\n",
      "\n",
      "dataset9.csv in ./AReM/cycling/ has an error: Error tokenizing data. C error: Expected 7 fields in line 485, saw 8\n",
      "\n",
      "dataset8.csv in ./AReM/sitting/ does not have 480 rows and 7 columns\n"
     ]
    }
   ],
   "source": [
    "dirs = ['bending1/', 'bending2/', 'cycling/', 'lying/', 'sitting/', 'standing/', 'walking/']\n",
    "for directory in dirs:\n",
    "    directory_path = f\"./AReM/{directory}\"\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            try:\n",
    "                df = pd.read_csv(os.path.join(directory_path, filename), skiprows=4, error_bad_lines=True)\n",
    "                if df.shape != (480, 7):\n",
    "                    print(f\"{filename} in {directory_path} does not have 480 rows and 7 columns\")\n",
    "                elif df.isnull().values.any():\n",
    "                    print(f\"{filename} in {directory_path} contains missing or null values\")\n",
    "            except pd.errors.ParserError as e:\n",
    "                print(f\"{filename} in {directory_path} has an error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several issues encountered in multiple datasets in AReM:\n",
    "\n",
    "\n",
    "_1. Missing or Null Values in'dataset4.csv in ./AReM/bending2/'_\n",
    "\n",
    "\n",
    "_2. ParserError catched using a try/except in 'dataset14.csv in ./AReM/cycling/'_ \n",
    "\n",
    "\n",
    "_3. ParserError catched using a try/except in 'dataset9.csv in ./AReM/cycling/'_\n",
    "\n",
    "\n",
    "_4. Shapes not aligned in 'dataset8.csv in ./AReM/sitting/'_\n",
    "\n",
    "\n",
    "The above issues will be resolved by implementing additional code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values in /AReM/bending2/dataset4.csv are not separated by commas, and are instead clustered together. the following Script will resolve this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cl = pd.read_csv('./AReM/bending2/dataset4.csv',skiprows=4)\n",
    "values_col = df_cl['# Columns: time']\n",
    "split_cols = values_col.str.split(expand=True)\n",
    "new_cols = ['col_{}'.format(i) for i in range(7)]\n",
    "split_cols.columns = new_cols\n",
    "df_cl = pd.concat([df_cl, split_cols], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Columns: time</th>\n",
       "      <th>avg_rss12</th>\n",
       "      <th>var_rss12</th>\n",
       "      <th>avg_rss13</th>\n",
       "      <th>var_rss13</th>\n",
       "      <th>avg_rss23</th>\n",
       "      <th>var_rss23</th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 32.50 0.50 0.00 0.00 19.00 1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>32.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250 32.50 0.50 0.00 0.00 18.50 0.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250</td>\n",
       "      <td>32.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.50</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500 32.75 0.43 1.00 0.00 18.00 0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500</td>\n",
       "      <td>32.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>750 32.50 0.50 0.00 0.00 17.50 0.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>750</td>\n",
       "      <td>32.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.50</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000 32.50 0.50 7.50 0.50 17.50 0.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000</td>\n",
       "      <td>32.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>7.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>17.50</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         # Columns: time  avg_rss12  var_rss12  avg_rss13  \\\n",
       "0     0 32.50 0.50 0.00 0.00 19.00 1.00         NaN        NaN        NaN   \n",
       "1   250 32.50 0.50 0.00 0.00 18.50 0.50         NaN        NaN        NaN   \n",
       "2   500 32.75 0.43 1.00 0.00 18.00 0.00         NaN        NaN        NaN   \n",
       "3   750 32.50 0.50 0.00 0.00 17.50 0.50         NaN        NaN        NaN   \n",
       "4  1000 32.50 0.50 7.50 0.50 17.50 0.87         NaN        NaN        NaN   \n",
       "\n",
       "   var_rss13  avg_rss23  var_rss23 col_0  col_1 col_2 col_3 col_4  col_5 col_6  \n",
       "0        NaN        NaN        NaN     0  32.50  0.50  0.00  0.00  19.00  1.00  \n",
       "1        NaN        NaN        NaN   250  32.50  0.50  0.00  0.00  18.50  0.50  \n",
       "2        NaN        NaN        NaN   500  32.75  0.43  1.00  0.00  18.00  0.00  \n",
       "3        NaN        NaN        NaN   750  32.50  0.50  0.00  0.00  17.50  0.50  \n",
       "4        NaN        NaN        NaN  1000  32.50  0.50  7.50  0.50  17.50  0.87  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cl.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cl= df_cl.drop(['# Columns: time','avg_rss12','var_rss12','avg_rss13','var_rss13','avg_rss23','var_rss23'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cl=df_cl.rename(columns={'col_0': '# Columns: time', 'col_1': 'avg_rss12','col_2': 'var_rss12','col_3': 'avg_rss13','col_4': 'var_rss13','col_5': 'avg_rss23','col_6': 'var_rss23'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Columns: time</th>\n",
       "      <th>avg_rss12</th>\n",
       "      <th>var_rss12</th>\n",
       "      <th>avg_rss13</th>\n",
       "      <th>var_rss13</th>\n",
       "      <th>avg_rss23</th>\n",
       "      <th>var_rss23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>32.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250</td>\n",
       "      <td>32.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.50</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>32.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>750</td>\n",
       "      <td>32.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.50</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>32.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>7.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>17.50</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  # Columns: time avg_rss12 var_rss12 avg_rss13 var_rss13 avg_rss23 var_rss23\n",
       "0               0     32.50      0.50      0.00      0.00     19.00      1.00\n",
       "1             250     32.50      0.50      0.00      0.00     18.50      0.50\n",
       "2             500     32.75      0.43      1.00      0.00     18.00      0.00\n",
       "3             750     32.50      0.50      0.00      0.00     17.50      0.50\n",
       "4            1000     32.50      0.50      7.50      0.50     17.50      0.87"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cl.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save new df as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cl.to_csv('./AReM/bending2/dataset4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on the issue number 2. The error suggests that the parser has encountered unexpected characters or structures in 'dataset14.csv in ./AReM/cycling/', and 'dataset9.csv in ./AReM/cycling/'. (e.g., missing values, extra commas, ...etc). \n",
    "\n",
    "Since I ran missing values test code above, we can narrow the type of error to ' extra commas'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 485 contains an extra comma: ['119750', '38.33', '0.94', '15.25', '2.17', '20.33', '1.25', '']\n"
     ]
    }
   ],
   "source": [
    "filename = './AReM/cycling/dataset9.csv'\n",
    "\n",
    "with open(filename, newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        # check if the row has extra commas\n",
    "        if len(row) > 7:\n",
    "            print(f\"Row {reader.line_num} contains an extra comma: {row}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 485 contains an extra comma: ['119750', '34.00', '2.12', '24.50', '1.80', '22.25', '2.59', '']\n"
     ]
    }
   ],
   "source": [
    "filename = './AReM/cycling/dataset14.csv'\n",
    "\n",
    "with open(filename, newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        # check if the row has extra commas\n",
    "        if len(row) > 7:\n",
    "            print(f\"Row {reader.line_num} contains an extra comma: {row}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra commas in row 485 are removed manually.\n",
    "\n",
    "Moving on the the last issue. Apparently in 'dataset8.csv in ./AReM/sitting/', the shape of the dataset doesn’t align With the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(479, 7)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_si = pd.read_csv('./AReM/sitting/dataset8.csv',skiprows=4)\n",
    "df_si.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After adding one row of time index 13500 between row 50 and 60 and using interpolate()\n",
    " [13500,42.00,0.00,17.56,2.69,17.27,3.42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 7)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_si2 = pd.read_csv('./AReM/sitting/dataset8.csv',skiprows=4)\n",
    "df_si2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 files processed with no issues. 0 files had issues.\n"
     ]
    }
   ],
   "source": [
    "dirs = ['bending1/', 'bending2/', 'cycling/', 'lying/', 'sitting/', 'standing/', 'walking/']\n",
    "num_files_processed = 0\n",
    "num_files_with_issues = 0\n",
    "\n",
    "for directory in dirs:\n",
    "    directory_path = f\"./AReM/{directory}\"\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            try:\n",
    "                df = pd.read_csv(os.path.join(directory_path, filename), skiprows=4, error_bad_lines=True)\n",
    "                if df.shape != (480, 7):\n",
    "                    print(f\"{filename} in {directory_path} does not have 480 rows and 7 columns\")\n",
    "                    num_files_with_issues += 1\n",
    "                elif df.isnull().values.any():\n",
    "                    print(f\"{filename} in {directory_path} contains missing or null values\")\n",
    "                    num_files_with_issues += 1\n",
    "                else:\n",
    "                    num_files_processed += 1\n",
    "            except pd.errors.ParserError as e:\n",
    "                print(f\"{filename} in {directory_path} has an error: {e}\")\n",
    "                num_files_with_issues += 1\n",
    "\n",
    "print(f\"{num_files_processed} files processed with no issues. {num_files_with_issues} files had issues.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # create an empty DataFrame to hold the combined data\n",
    "# combined_Or_df = pd.DataFrame()\n",
    "\n",
    "# # define the directories to loop through\n",
    "# dirs = ['./AReM/bending1/', './AReM/bending2/', './AReM/cycling/', './AReM/lying/', './AReM/sitting/', './AReM/standing/', './AReM/walking/']\n",
    "\n",
    "# # loop through the directories\n",
    "# for d in dirs:\n",
    "#     # get the path to the directory\n",
    "#     path = os.path.join(os.getcwd(), d)\n",
    "    \n",
    "#     # loop through the CSV files in the directory\n",
    "#     for filename in os.listdir(path):\n",
    "#         if filename.endswith(\".csv\"):\n",
    "#             # read the CSV file into a DataFrame\n",
    "#             df = pd.read_csv(os.path.join(path, filename),skiprows=4)\n",
    "            \n",
    "#             # add a column to identify which directory the data came from\n",
    "#             df[\"activity\"] = d.strip(\"/\")\n",
    "            \n",
    "#             # append the DataFrame to the combined DataFrame\n",
    "#             combined_Or_df = combined_Or_df.append(df, ignore_index=True)\n",
    "\n",
    "# # display the combined DataFrame\n",
    "# combined_Or_df\n",
    "# # combined_Or_df = combined_df.drop(\"activity\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty DataFrame to hold the combined data\n",
    "comb_df = pd.DataFrame()\n",
    "\n",
    "# define the directories to loop through\n",
    "dirs = ['./AReM/bending1/', './AReM/bending2/', './AReM/cycling/', './AReM/lying/', './AReM/sitting/', './AReM/standing/', './AReM/walking/']\n",
    "\n",
    "# loop through the directories\n",
    "for d in dirs:\n",
    "    # get the path to the directory\n",
    "    path = os.path.join(os.getcwd(), d)\n",
    "    \n",
    "    # loop through the CSV files in the directory\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            # read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(os.path.join(path, filename),skiprows=4)\n",
    "            \n",
    "            # add a column to identify which directory the data came from\n",
    "            activity = d.strip(\"/\") + '_' + filename.split('.')[0]\n",
    "            df[\"activity\"] = activity\n",
    "            \n",
    "            # append the DataFrame to the combined DataFrame\n",
    "            comb_df = comb_df.append(df, ignore_index=True)\n",
    "comb_df=comb_df.drop(\"# Columns: time\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_rss12</th>\n",
       "      <th>var_rss12</th>\n",
       "      <th>avg_rss13</th>\n",
       "      <th>var_rss13</th>\n",
       "      <th>avg_rss23</th>\n",
       "      <th>var_rss23</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>./AReM/bending1_dataset7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.33</td>\n",
       "      <td>0.94</td>\n",
       "      <td>./AReM/bending1_dataset7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>16.75</td>\n",
       "      <td>1.79</td>\n",
       "      <td>18.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>./AReM/bending1_dataset7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>16.75</td>\n",
       "      <td>0.83</td>\n",
       "      <td>19.00</td>\n",
       "      <td>1.22</td>\n",
       "      <td>./AReM/bending1_dataset7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43.00</td>\n",
       "      <td>0.82</td>\n",
       "      <td>16.25</td>\n",
       "      <td>0.83</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>./AReM/bending1_dataset7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42235</th>\n",
       "      <td>31.50</td>\n",
       "      <td>1.66</td>\n",
       "      <td>12.50</td>\n",
       "      <td>3.20</td>\n",
       "      <td>14.25</td>\n",
       "      <td>4.44</td>\n",
       "      <td>./AReM/walking_dataset9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42236</th>\n",
       "      <td>27.33</td>\n",
       "      <td>1.25</td>\n",
       "      <td>11.33</td>\n",
       "      <td>0.94</td>\n",
       "      <td>20.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>./AReM/walking_dataset9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42237</th>\n",
       "      <td>37.80</td>\n",
       "      <td>7.68</td>\n",
       "      <td>14.20</td>\n",
       "      <td>2.48</td>\n",
       "      <td>17.25</td>\n",
       "      <td>0.83</td>\n",
       "      <td>./AReM/walking_dataset9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42238</th>\n",
       "      <td>33.75</td>\n",
       "      <td>1.30</td>\n",
       "      <td>15.75</td>\n",
       "      <td>5.21</td>\n",
       "      <td>16.50</td>\n",
       "      <td>2.69</td>\n",
       "      <td>./AReM/walking_dataset9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42239</th>\n",
       "      <td>32.67</td>\n",
       "      <td>3.09</td>\n",
       "      <td>18.67</td>\n",
       "      <td>0.47</td>\n",
       "      <td>14.00</td>\n",
       "      <td>3.16</td>\n",
       "      <td>./AReM/walking_dataset9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42240 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  var_rss23  \\\n",
       "0          42.00       0.00      18.50       0.50      12.00       0.00   \n",
       "1          42.00       0.00      18.00       0.00      11.33       0.94   \n",
       "2          42.75       0.43      16.75       1.79      18.25       0.43   \n",
       "3          42.50       0.50      16.75       0.83      19.00       1.22   \n",
       "4          43.00       0.82      16.25       0.83      18.00       0.00   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "42235      31.50       1.66      12.50       3.20      14.25       4.44   \n",
       "42236      27.33       1.25      11.33       0.94      20.00       4.00   \n",
       "42237      37.80       7.68      14.20       2.48      17.25       0.83   \n",
       "42238      33.75       1.30      15.75       5.21      16.50       2.69   \n",
       "42239      32.67       3.09      18.67       0.47      14.00       3.16   \n",
       "\n",
       "                       activity  \n",
       "0      ./AReM/bending1_dataset7  \n",
       "1      ./AReM/bending1_dataset7  \n",
       "2      ./AReM/bending1_dataset7  \n",
       "3      ./AReM/bending1_dataset7  \n",
       "4      ./AReM/bending1_dataset7  \n",
       "...                         ...  \n",
       "42235   ./AReM/walking_dataset9  \n",
       "42236   ./AReM/walking_dataset9  \n",
       "42237   ./AReM/walking_dataset9  \n",
       "42238   ./AReM/walking_dataset9  \n",
       "42239   ./AReM/walking_dataset9  \n",
       "\n",
       "[42240 rows x 7 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Test and Train Data\n",
    "Keep datasets 1 and 2 in folders bending1 and bending 2, as well as datasets 1,\n",
    "2, and 3 in other folders as test data and other datasets as train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_directories = [\"./AReM_Copy/bending1/\", \"./AReM_Copy/bending2/\"]\n",
    "for path in paths_to_directories:\n",
    "    os.makedirs(os.path.join(path, \"train_data\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(path, \"test_data\"), exist_ok=True)\n",
    "    path_to_train_data = os.path.join(path, \"train_data\")\n",
    "    path_to_test_data = os.path.join(path, \"test_data\")\n",
    "    num_datasets = len([filename for filename in os.listdir(path) if filename.startswith(\"dataset\")])\n",
    "    for i in range(1, num_datasets + 1):\n",
    "        if i in [1,2]:\n",
    "            shutil.move(os.path.join(path, f\"dataset{i}.csv\"), os.path.join(path_to_test_data, f\"dataset{i}.csv\"))\n",
    "        else:\n",
    "            shutil.move(os.path.join(path, f\"dataset{i}.csv\"), os.path.join(path_to_train_data, f\"dataset{i}.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_directories = [\"./AReM_Copy/cycling/\", \"./AReM_Copy/lying/\",\"./AReM_Copy/sitting/\",\"./AReM_Copy/standing/\",\"./AReM_Copy/walking/\"]\n",
    "for path in paths_to_directories:\n",
    "    os.makedirs(os.path.join(path, \"train_data\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(path, \"test_data\"), exist_ok=True)\n",
    "    path_to_train_data = os.path.join(path, \"train_data\")\n",
    "    path_to_test_data = os.path.join(path, \"test_data\")\n",
    "    num_datasets = len([filename for filename in os.listdir(path) if filename.startswith(\"dataset\")])\n",
    "    for i in range(1, num_datasets + 1):\n",
    "        if i in [1,2,3]:\n",
    "            shutil.move(os.path.join(path, f\"dataset{i}.csv\"), os.path.join(path_to_test_data, f\"dataset{i}.csv\"))\n",
    "        else:\n",
    "            shutil.move(os.path.join(path, f\"dataset{i}.csv\"), os.path.join(path_to_train_data, f\"dataset{i}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42240\n",
      "test_data = 9120,traint_data =33120\n"
     ]
    }
   ],
   "source": [
    "data_frames_train = []\n",
    "data_frames_test = []\n",
    "\n",
    "# Loop over each directory in AReM_Copy\n",
    "for directory in os.listdir('./AReM_Copy/'):\n",
    "    if not os.path.isdir(os.path.join('./AReM_Copy', directory)):\n",
    "        continue\n",
    "    for subdirectory in os.listdir(os.path.join('./AReM_Copy', directory)):\n",
    "        if not os.path.isdir(os.path.join('./AReM_Copy', directory, subdirectory)):\n",
    "            continue\n",
    "            \n",
    "        path_to_csv_files = os.path.join('./AReM_Copy', directory, subdirectory)\n",
    "        \n",
    "        for csv_file in os.listdir(path_to_csv_files):\n",
    "            if not csv_file.endswith('.csv'):\n",
    "                continue\n",
    "                \n",
    "            path_to_csv_file = os.path.join(path_to_csv_files, csv_file)\n",
    "            df = pd.read_csv(path_to_csv_file, skiprows=4)\n",
    "            if subdirectory == 'train_data':\n",
    "                data_frames_train.append(df)\n",
    "            elif subdirectory == 'test_data':\n",
    "                data_frames_test.append(df)\n",
    "train_data = pd.concat(data_frames_train, axis=0)\n",
    "test_data = pd.concat(data_frames_test, axis=0)\n",
    "combined_df = pd.concat([test_data, train_data], ignore_index=True)\n",
    "print(len(combined_df))\n",
    "print(f'test_data = {len(test_data)},traint_data ={len(train_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_rss12</th>\n",
       "      <th>var_rss12</th>\n",
       "      <th>avg_rss13</th>\n",
       "      <th>var_rss13</th>\n",
       "      <th>avg_rss23</th>\n",
       "      <th>var_rss23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>22.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>33.75</td>\n",
       "      <td>1.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>23.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>23.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>23.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>24.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42235</th>\n",
       "      <td>41.75</td>\n",
       "      <td>1.79</td>\n",
       "      <td>11.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>16.67</td>\n",
       "      <td>2.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42236</th>\n",
       "      <td>36.33</td>\n",
       "      <td>0.47</td>\n",
       "      <td>16.00</td>\n",
       "      <td>3.16</td>\n",
       "      <td>20.33</td>\n",
       "      <td>1.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42237</th>\n",
       "      <td>31.50</td>\n",
       "      <td>1.50</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.25</td>\n",
       "      <td>7.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42238</th>\n",
       "      <td>34.25</td>\n",
       "      <td>6.38</td>\n",
       "      <td>12.67</td>\n",
       "      <td>2.49</td>\n",
       "      <td>15.25</td>\n",
       "      <td>4.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42239</th>\n",
       "      <td>38.33</td>\n",
       "      <td>0.94</td>\n",
       "      <td>15.25</td>\n",
       "      <td>2.17</td>\n",
       "      <td>20.33</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42240 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  var_rss23\n",
       "0          39.25       0.43      22.75       0.43      33.75       1.30\n",
       "1          39.25       0.43      23.00       0.00      33.00       0.00\n",
       "2          39.25       0.43      23.25       0.43      33.00       0.00\n",
       "3          39.50       0.50      23.00       0.71      33.00       0.00\n",
       "4          39.50       0.50      24.00       0.00      33.00       0.00\n",
       "...          ...        ...        ...        ...        ...        ...\n",
       "42235      41.75       1.79      11.00       6.00      16.67       2.49\n",
       "42236      36.33       0.47      16.00       3.16      20.33       1.70\n",
       "42237      31.50       1.50      21.00       0.00      12.25       7.12\n",
       "42238      34.25       6.38      12.67       2.49      15.25       4.21\n",
       "42239      38.33       0.94      15.25       2.17      20.33       1.25\n",
       "\n",
       "[42240 rows x 6 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_no_indx = combined_df.drop('# Columns: time', axis=1)\n",
    "combined_df_no_indx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Feature Extraction\n",
    "\n",
    "Classification of time series usually needs extracting features from them. In this\n",
    "problem, we focus on time-domain features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### i. Research\n",
    "Research what types of time-domain features are usually used in time series\n",
    "classification and list them (examples are minimum, maximum, mean, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_When we want to classify time series data, we need to extract features that describe the shape and patterns in the data. These features can be classified into different categories such as Time-domain features, Frequency Domain Features, and Model-Based Feature._\n",
    "\n",
    "\n",
    "\n",
    "Here are some common time-domain features that can be computed for a time series dataset:\n",
    "\n",
    "Mean: The mean of the signal over a given time interval.\n",
    "\n",
    "Variance: The variance of the signal over a given time interval.\n",
    "\n",
    "Standard deviation: The standard deviation of the signal over a given time interval.\n",
    "\n",
    "Minimum value: The minimum value of the signal over a given time interval.\n",
    "\n",
    "Maximum value: The maximum value of the signal over a given time interval.\n",
    "\n",
    "Root mean square (RMS) value: The square root of the mean of the squared values of the signal over a given time interval.\n",
    "\n",
    "Skewness: A measure of the asymmetry of the signal over a given time interval.\n",
    "\n",
    "Kurtosis: A measure of the \"peakedness\" of the signal over a given time interval.\n",
    "\n",
    "Zero crossing rate: The rate at which the signal crosses the zero value over a given time interval.\n",
    "\n",
    "Auto-correlation: A measure of the similarity between the signal and a delayed version of itself over a given time interval.<font color='blue'>\n",
    "\n",
    "These features can provide information about the statistical properties, shape, and dynamics of the time series, and can be used to characterize the signal and discriminate between different classes of time series data.\n",
    "    \n",
    "<font color='green'> Sources: \n",
    "    - https://stats.stackexchange.com/questions/50807/features-for-time-series-classification\n",
    "    - https://jneuroengrehab.biomedcentral.com/articles/10.1186/1743-0003-7-21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ii. Extraction\n",
    "Extract the time-domain features minimum, maximum, mean, median, standard deviation, first quartile, and third quartile for all of the 6 time series\n",
    "in each instance. You are free to normalize/standardize features or use them\n",
    "directly.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>avg_rss12_min</th>\n",
       "      <th>avg_rss12_max</th>\n",
       "      <th>avg_rss12_mean</th>\n",
       "      <th>avg_rss12_median</th>\n",
       "      <th>avg_rss12_std</th>\n",
       "      <th>avg_rss12_q1</th>\n",
       "      <th>avg_rss12_q3</th>\n",
       "      <th>var_rss12_min</th>\n",
       "      <th>var_rss12_max</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_rss23_std</th>\n",
       "      <th>avg_rss23_q1</th>\n",
       "      <th>avg_rss23_q3</th>\n",
       "      <th>var_rss23_min</th>\n",
       "      <th>var_rss23_max</th>\n",
       "      <th>var_rss23_mean</th>\n",
       "      <th>var_rss23_median</th>\n",
       "      <th>var_rss23_std</th>\n",
       "      <th>var_rss23_q1</th>\n",
       "      <th>var_rss23_q3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./AReM/bending1_dataset1</td>\n",
       "      <td>37.25</td>\n",
       "      <td>45.00</td>\n",
       "      <td>40.624792</td>\n",
       "      <td>40.500</td>\n",
       "      <td>1.476967</td>\n",
       "      <td>39.25</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.30</td>\n",
       "      <td>...</td>\n",
       "      <td>2.188449</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>36.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.570583</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.582915</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./AReM/bending1_dataset2</td>\n",
       "      <td>38.00</td>\n",
       "      <td>45.67</td>\n",
       "      <td>42.812812</td>\n",
       "      <td>42.500</td>\n",
       "      <td>1.435550</td>\n",
       "      <td>42.00</td>\n",
       "      <td>43.6700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.22</td>\n",
       "      <td>...</td>\n",
       "      <td>1.995255</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>34.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.571083</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.601010</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./AReM/bending1_dataset3</td>\n",
       "      <td>35.00</td>\n",
       "      <td>47.40</td>\n",
       "      <td>43.954500</td>\n",
       "      <td>44.330</td>\n",
       "      <td>1.558835</td>\n",
       "      <td>43.00</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.70</td>\n",
       "      <td>...</td>\n",
       "      <td>1.999604</td>\n",
       "      <td>35.3625</td>\n",
       "      <td>36.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.493292</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.513506</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.9400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./AReM/bending1_dataset4</td>\n",
       "      <td>33.00</td>\n",
       "      <td>47.75</td>\n",
       "      <td>42.179813</td>\n",
       "      <td>43.500</td>\n",
       "      <td>3.670666</td>\n",
       "      <td>39.15</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.849448</td>\n",
       "      <td>30.4575</td>\n",
       "      <td>36.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.613521</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.524317</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./AReM/bending1_dataset5</td>\n",
       "      <td>33.00</td>\n",
       "      <td>45.75</td>\n",
       "      <td>41.678063</td>\n",
       "      <td>41.750</td>\n",
       "      <td>2.243490</td>\n",
       "      <td>41.33</td>\n",
       "      <td>42.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.83</td>\n",
       "      <td>...</td>\n",
       "      <td>2.411026</td>\n",
       "      <td>28.4575</td>\n",
       "      <td>31.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.383292</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.389164</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>./AReM/walking_dataset5</td>\n",
       "      <td>20.75</td>\n",
       "      <td>46.25</td>\n",
       "      <td>34.763333</td>\n",
       "      <td>35.290</td>\n",
       "      <td>4.742208</td>\n",
       "      <td>31.67</td>\n",
       "      <td>38.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.68</td>\n",
       "      <td>...</td>\n",
       "      <td>3.174681</td>\n",
       "      <td>14.2500</td>\n",
       "      <td>18.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.39</td>\n",
       "      <td>3.288271</td>\n",
       "      <td>3.270</td>\n",
       "      <td>1.647528</td>\n",
       "      <td>2.05</td>\n",
       "      <td>4.3050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>./AReM/walking_dataset6</td>\n",
       "      <td>21.50</td>\n",
       "      <td>51.00</td>\n",
       "      <td>34.935812</td>\n",
       "      <td>35.500</td>\n",
       "      <td>4.645944</td>\n",
       "      <td>32.00</td>\n",
       "      <td>38.0625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.21</td>\n",
       "      <td>...</td>\n",
       "      <td>3.192058</td>\n",
       "      <td>14.2375</td>\n",
       "      <td>18.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.21</td>\n",
       "      <td>3.280021</td>\n",
       "      <td>3.015</td>\n",
       "      <td>1.700918</td>\n",
       "      <td>2.12</td>\n",
       "      <td>4.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>./AReM/walking_dataset7</td>\n",
       "      <td>18.33</td>\n",
       "      <td>47.67</td>\n",
       "      <td>34.333042</td>\n",
       "      <td>34.750</td>\n",
       "      <td>4.948770</td>\n",
       "      <td>31.25</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.48</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000493</td>\n",
       "      <td>13.7500</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.01</td>\n",
       "      <td>3.261583</td>\n",
       "      <td>2.980</td>\n",
       "      <td>1.617290</td>\n",
       "      <td>2.05</td>\n",
       "      <td>4.3200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>./AReM/walking_dataset8</td>\n",
       "      <td>18.33</td>\n",
       "      <td>45.75</td>\n",
       "      <td>34.599875</td>\n",
       "      <td>35.125</td>\n",
       "      <td>4.731790</td>\n",
       "      <td>31.50</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.37</td>\n",
       "      <td>...</td>\n",
       "      <td>2.905688</td>\n",
       "      <td>14.0000</td>\n",
       "      <td>18.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.86</td>\n",
       "      <td>3.289542</td>\n",
       "      <td>3.015</td>\n",
       "      <td>1.680170</td>\n",
       "      <td>2.12</td>\n",
       "      <td>4.2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>./AReM/walking_dataset9</td>\n",
       "      <td>15.50</td>\n",
       "      <td>43.67</td>\n",
       "      <td>34.225875</td>\n",
       "      <td>34.750</td>\n",
       "      <td>4.441798</td>\n",
       "      <td>31.25</td>\n",
       "      <td>37.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.24</td>\n",
       "      <td>...</td>\n",
       "      <td>2.992920</td>\n",
       "      <td>14.3300</td>\n",
       "      <td>18.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.42</td>\n",
       "      <td>3.479542</td>\n",
       "      <td>3.270</td>\n",
       "      <td>1.761146</td>\n",
       "      <td>2.24</td>\n",
       "      <td>4.5375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    activity  avg_rss12_min  avg_rss12_max  avg_rss12_mean  \\\n",
       "0   ./AReM/bending1_dataset1          37.25          45.00       40.624792   \n",
       "1   ./AReM/bending1_dataset2          38.00          45.67       42.812812   \n",
       "2   ./AReM/bending1_dataset3          35.00          47.40       43.954500   \n",
       "3   ./AReM/bending1_dataset4          33.00          47.75       42.179813   \n",
       "4   ./AReM/bending1_dataset5          33.00          45.75       41.678063   \n",
       "..                       ...            ...            ...             ...   \n",
       "83   ./AReM/walking_dataset5          20.75          46.25       34.763333   \n",
       "84   ./AReM/walking_dataset6          21.50          51.00       34.935812   \n",
       "85   ./AReM/walking_dataset7          18.33          47.67       34.333042   \n",
       "86   ./AReM/walking_dataset8          18.33          45.75       34.599875   \n",
       "87   ./AReM/walking_dataset9          15.50          43.67       34.225875   \n",
       "\n",
       "    avg_rss12_median  avg_rss12_std  avg_rss12_q1  avg_rss12_q3  \\\n",
       "0             40.500       1.476967         39.25       42.0000   \n",
       "1             42.500       1.435550         42.00       43.6700   \n",
       "2             44.330       1.558835         43.00       45.0000   \n",
       "3             43.500       3.670666         39.15       45.0000   \n",
       "4             41.750       2.243490         41.33       42.7500   \n",
       "..               ...            ...           ...           ...   \n",
       "83            35.290       4.742208         31.67       38.2500   \n",
       "84            35.500       4.645944         32.00       38.0625   \n",
       "85            34.750       4.948770         31.25       38.0000   \n",
       "86            35.125       4.731790         31.50       38.0000   \n",
       "87            34.750       4.441798         31.25       37.2500   \n",
       "\n",
       "    var_rss12_min  var_rss12_max  ...  avg_rss23_std  avg_rss23_q1  \\\n",
       "0             0.0           1.30  ...       2.188449       33.0000   \n",
       "1             0.0           1.22  ...       1.995255       32.0000   \n",
       "2             0.0           1.70  ...       1.999604       35.3625   \n",
       "3             0.0           3.00  ...       3.849448       30.4575   \n",
       "4             0.0           2.83  ...       2.411026       28.4575   \n",
       "..            ...            ...  ...            ...           ...   \n",
       "83            0.0          12.68  ...       3.174681       14.2500   \n",
       "84            0.0          12.21  ...       3.192058       14.2375   \n",
       "85            0.0          12.48  ...       3.000493       13.7500   \n",
       "86            0.0          15.37  ...       2.905688       14.0000   \n",
       "87            0.0          17.24  ...       2.992920       14.3300   \n",
       "\n",
       "    avg_rss23_q3  var_rss23_min  var_rss23_max  var_rss23_mean  \\\n",
       "0          36.00            0.0           1.92        0.570583   \n",
       "1          34.50            0.0           3.11        0.571083   \n",
       "2          36.50            0.0           1.79        0.493292   \n",
       "3          36.33            0.0           2.18        0.613521   \n",
       "4          31.25            0.0           1.79        0.383292   \n",
       "..           ...            ...            ...             ...   \n",
       "83         18.33            0.0           9.39        3.288271   \n",
       "84         18.25            0.0          10.21        3.280021   \n",
       "85         18.00            0.0           8.01        3.261583   \n",
       "86         18.25            0.0           8.86        3.289542   \n",
       "87         18.25            0.0           9.42        3.479542   \n",
       "\n",
       "    var_rss23_median  var_rss23_std  var_rss23_q1  var_rss23_q3  \n",
       "0              0.430       0.582915          0.00        1.3000  \n",
       "1              0.430       0.601010          0.00        1.3000  \n",
       "2              0.430       0.513506          0.00        0.9400  \n",
       "3              0.500       0.524317          0.00        1.0000  \n",
       "4              0.430       0.389164          0.00        0.5000  \n",
       "..               ...            ...           ...           ...  \n",
       "83             3.270       1.647528          2.05        4.3050  \n",
       "84             3.015       1.700918          2.12        4.5000  \n",
       "85             2.980       1.617290          2.05        4.3200  \n",
       "86             3.015       1.680170          2.12        4.2600  \n",
       "87             3.270       1.761146          2.24        4.5375  \n",
       "\n",
       "[88 rows x 43 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# define the columns to calculate the statistics for\n",
    "cols = ['avg_rss12', 'var_rss12', 'avg_rss13', 'var_rss13', 'avg_rss23', 'var_rss23']\n",
    "\n",
    "# group the data based on the activity column and calculate the statistics for each group\n",
    "stats_df = comb_df[cols + ['activity']].groupby('activity').agg([np.min, np.max, np.mean, np.median, np.std, lambda x: np.percentile(x, 25), lambda x: np.percentile(x, 75)])\n",
    "\n",
    "# rename the columns to include the respective statistics\n",
    "new_cols = [col + '_' + stat for col in cols for stat in ['min', 'max', 'mean', 'median', 'std', 'q1', 'q3']]\n",
    "stats_df.columns = new_cols\n",
    "\n",
    "# reset the index to make the activity column a regular column\n",
    "stats_df = stats_df.reset_index()\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df_noIndex = stats_df.drop('activity', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_rss12_min</th>\n",
       "      <th>avg_rss12_max</th>\n",
       "      <th>avg_rss12_mean</th>\n",
       "      <th>avg_rss12_median</th>\n",
       "      <th>avg_rss12_std</th>\n",
       "      <th>avg_rss12_q1</th>\n",
       "      <th>avg_rss12_q3</th>\n",
       "      <th>var_rss12_min</th>\n",
       "      <th>var_rss12_max</th>\n",
       "      <th>var_rss12_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_rss23_std</th>\n",
       "      <th>avg_rss23_q1</th>\n",
       "      <th>avg_rss23_q3</th>\n",
       "      <th>var_rss23_min</th>\n",
       "      <th>var_rss23_max</th>\n",
       "      <th>var_rss23_mean</th>\n",
       "      <th>var_rss23_median</th>\n",
       "      <th>var_rss23_std</th>\n",
       "      <th>var_rss23_q1</th>\n",
       "      <th>var_rss23_q3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.25</td>\n",
       "      <td>45.00</td>\n",
       "      <td>40.624792</td>\n",
       "      <td>40.500</td>\n",
       "      <td>1.476967</td>\n",
       "      <td>39.25</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.358604</td>\n",
       "      <td>...</td>\n",
       "      <td>2.188449</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>36.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.570583</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.582915</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.00</td>\n",
       "      <td>45.67</td>\n",
       "      <td>42.812812</td>\n",
       "      <td>42.500</td>\n",
       "      <td>1.435550</td>\n",
       "      <td>42.00</td>\n",
       "      <td>43.6700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.372438</td>\n",
       "      <td>...</td>\n",
       "      <td>1.995255</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>34.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.571083</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.601010</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.00</td>\n",
       "      <td>47.40</td>\n",
       "      <td>43.954500</td>\n",
       "      <td>44.330</td>\n",
       "      <td>1.558835</td>\n",
       "      <td>43.00</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.426250</td>\n",
       "      <td>...</td>\n",
       "      <td>1.999604</td>\n",
       "      <td>35.3625</td>\n",
       "      <td>36.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.493292</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.513506</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.9400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.00</td>\n",
       "      <td>47.75</td>\n",
       "      <td>42.179813</td>\n",
       "      <td>43.500</td>\n",
       "      <td>3.670666</td>\n",
       "      <td>39.15</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.696042</td>\n",
       "      <td>...</td>\n",
       "      <td>3.849448</td>\n",
       "      <td>30.4575</td>\n",
       "      <td>36.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.613521</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.524317</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.00</td>\n",
       "      <td>45.75</td>\n",
       "      <td>41.678063</td>\n",
       "      <td>41.750</td>\n",
       "      <td>2.243490</td>\n",
       "      <td>41.33</td>\n",
       "      <td>42.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.535979</td>\n",
       "      <td>...</td>\n",
       "      <td>2.411026</td>\n",
       "      <td>28.4575</td>\n",
       "      <td>31.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.383292</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.389164</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>20.75</td>\n",
       "      <td>46.25</td>\n",
       "      <td>34.763333</td>\n",
       "      <td>35.290</td>\n",
       "      <td>4.742208</td>\n",
       "      <td>31.67</td>\n",
       "      <td>38.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.68</td>\n",
       "      <td>4.223792</td>\n",
       "      <td>...</td>\n",
       "      <td>3.174681</td>\n",
       "      <td>14.2500</td>\n",
       "      <td>18.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.39</td>\n",
       "      <td>3.288271</td>\n",
       "      <td>3.270</td>\n",
       "      <td>1.647528</td>\n",
       "      <td>2.05</td>\n",
       "      <td>4.3050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>21.50</td>\n",
       "      <td>51.00</td>\n",
       "      <td>34.935812</td>\n",
       "      <td>35.500</td>\n",
       "      <td>4.645944</td>\n",
       "      <td>32.00</td>\n",
       "      <td>38.0625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.21</td>\n",
       "      <td>4.115750</td>\n",
       "      <td>...</td>\n",
       "      <td>3.192058</td>\n",
       "      <td>14.2375</td>\n",
       "      <td>18.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.21</td>\n",
       "      <td>3.280021</td>\n",
       "      <td>3.015</td>\n",
       "      <td>1.700918</td>\n",
       "      <td>2.12</td>\n",
       "      <td>4.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>18.33</td>\n",
       "      <td>47.67</td>\n",
       "      <td>34.333042</td>\n",
       "      <td>34.750</td>\n",
       "      <td>4.948770</td>\n",
       "      <td>31.25</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.48</td>\n",
       "      <td>4.396958</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000493</td>\n",
       "      <td>13.7500</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.01</td>\n",
       "      <td>3.261583</td>\n",
       "      <td>2.980</td>\n",
       "      <td>1.617290</td>\n",
       "      <td>2.05</td>\n",
       "      <td>4.3200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>18.33</td>\n",
       "      <td>45.75</td>\n",
       "      <td>34.599875</td>\n",
       "      <td>35.125</td>\n",
       "      <td>4.731790</td>\n",
       "      <td>31.50</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.37</td>\n",
       "      <td>4.398833</td>\n",
       "      <td>...</td>\n",
       "      <td>2.905688</td>\n",
       "      <td>14.0000</td>\n",
       "      <td>18.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.86</td>\n",
       "      <td>3.289542</td>\n",
       "      <td>3.015</td>\n",
       "      <td>1.680170</td>\n",
       "      <td>2.12</td>\n",
       "      <td>4.2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>15.50</td>\n",
       "      <td>43.67</td>\n",
       "      <td>34.225875</td>\n",
       "      <td>34.750</td>\n",
       "      <td>4.441798</td>\n",
       "      <td>31.25</td>\n",
       "      <td>37.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.24</td>\n",
       "      <td>4.354500</td>\n",
       "      <td>...</td>\n",
       "      <td>2.992920</td>\n",
       "      <td>14.3300</td>\n",
       "      <td>18.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.42</td>\n",
       "      <td>3.479542</td>\n",
       "      <td>3.270</td>\n",
       "      <td>1.761146</td>\n",
       "      <td>2.24</td>\n",
       "      <td>4.5375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    avg_rss12_min  avg_rss12_max  avg_rss12_mean  avg_rss12_median  \\\n",
       "0           37.25          45.00       40.624792            40.500   \n",
       "1           38.00          45.67       42.812812            42.500   \n",
       "2           35.00          47.40       43.954500            44.330   \n",
       "3           33.00          47.75       42.179813            43.500   \n",
       "4           33.00          45.75       41.678063            41.750   \n",
       "..            ...            ...             ...               ...   \n",
       "83          20.75          46.25       34.763333            35.290   \n",
       "84          21.50          51.00       34.935812            35.500   \n",
       "85          18.33          47.67       34.333042            34.750   \n",
       "86          18.33          45.75       34.599875            35.125   \n",
       "87          15.50          43.67       34.225875            34.750   \n",
       "\n",
       "    avg_rss12_std  avg_rss12_q1  avg_rss12_q3  var_rss12_min  var_rss12_max  \\\n",
       "0        1.476967         39.25       42.0000            0.0           1.30   \n",
       "1        1.435550         42.00       43.6700            0.0           1.22   \n",
       "2        1.558835         43.00       45.0000            0.0           1.70   \n",
       "3        3.670666         39.15       45.0000            0.0           3.00   \n",
       "4        2.243490         41.33       42.7500            0.0           2.83   \n",
       "..            ...           ...           ...            ...            ...   \n",
       "83       4.742208         31.67       38.2500            0.0          12.68   \n",
       "84       4.645944         32.00       38.0625            0.0          12.21   \n",
       "85       4.948770         31.25       38.0000            0.0          12.48   \n",
       "86       4.731790         31.50       38.0000            0.0          15.37   \n",
       "87       4.441798         31.25       37.2500            0.0          17.24   \n",
       "\n",
       "    var_rss12_mean  ...  avg_rss23_std  avg_rss23_q1  avg_rss23_q3  \\\n",
       "0         0.358604  ...       2.188449       33.0000         36.00   \n",
       "1         0.372438  ...       1.995255       32.0000         34.50   \n",
       "2         0.426250  ...       1.999604       35.3625         36.50   \n",
       "3         0.696042  ...       3.849448       30.4575         36.33   \n",
       "4         0.535979  ...       2.411026       28.4575         31.25   \n",
       "..             ...  ...            ...           ...           ...   \n",
       "83        4.223792  ...       3.174681       14.2500         18.33   \n",
       "84        4.115750  ...       3.192058       14.2375         18.25   \n",
       "85        4.396958  ...       3.000493       13.7500         18.00   \n",
       "86        4.398833  ...       2.905688       14.0000         18.25   \n",
       "87        4.354500  ...       2.992920       14.3300         18.25   \n",
       "\n",
       "    var_rss23_min  var_rss23_max  var_rss23_mean  var_rss23_median  \\\n",
       "0             0.0           1.92        0.570583             0.430   \n",
       "1             0.0           3.11        0.571083             0.430   \n",
       "2             0.0           1.79        0.493292             0.430   \n",
       "3             0.0           2.18        0.613521             0.500   \n",
       "4             0.0           1.79        0.383292             0.430   \n",
       "..            ...            ...             ...               ...   \n",
       "83            0.0           9.39        3.288271             3.270   \n",
       "84            0.0          10.21        3.280021             3.015   \n",
       "85            0.0           8.01        3.261583             2.980   \n",
       "86            0.0           8.86        3.289542             3.015   \n",
       "87            0.0           9.42        3.479542             3.270   \n",
       "\n",
       "    var_rss23_std  var_rss23_q1  var_rss23_q3  \n",
       "0        0.582915          0.00        1.3000  \n",
       "1        0.601010          0.00        1.3000  \n",
       "2        0.513506          0.00        0.9400  \n",
       "3        0.524317          0.00        1.0000  \n",
       "4        0.389164          0.00        0.5000  \n",
       "..            ...           ...           ...  \n",
       "83       1.647528          2.05        4.3050  \n",
       "84       1.700918          2.12        4.5000  \n",
       "85       1.617290          2.05        4.3200  \n",
       "86       1.680170          2.12        4.2600  \n",
       "87       1.761146          2.24        4.5375  \n",
       "\n",
       "[88 rows x 42 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### iii. Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>std</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>avg_rss12_min</td>\n",
       "      <td>9.515445</td>\n",
       "      <td>8.316092</td>\n",
       "      <td>10.829000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>avg_rss12_max</td>\n",
       "      <td>4.369322</td>\n",
       "      <td>3.459442</td>\n",
       "      <td>5.431541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avg_rss12_mean</td>\n",
       "      <td>5.305300</td>\n",
       "      <td>4.749321</td>\n",
       "      <td>5.919256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avg_rss12_median</td>\n",
       "      <td>5.409056</td>\n",
       "      <td>4.854978</td>\n",
       "      <td>6.058866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avg_rss12_std</td>\n",
       "      <td>1.762057</td>\n",
       "      <td>1.578340</td>\n",
       "      <td>1.958987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>avg_rss12_q1</td>\n",
       "      <td>6.118526</td>\n",
       "      <td>5.635953</td>\n",
       "      <td>6.688424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>avg_rss12_q3</td>\n",
       "      <td>5.109643</td>\n",
       "      <td>4.417823</td>\n",
       "      <td>5.912804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>var_rss12_min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>var_rss12_max</td>\n",
       "      <td>5.033882</td>\n",
       "      <td>4.690841</td>\n",
       "      <td>5.468741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>var_rss12_mean</td>\n",
       "      <td>1.565200</td>\n",
       "      <td>1.436794</td>\n",
       "      <td>1.742884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>var_rss12_median</td>\n",
       "      <td>1.404197</td>\n",
       "      <td>1.273639</td>\n",
       "      <td>1.579537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>var_rss12_std</td>\n",
       "      <td>0.879066</td>\n",
       "      <td>0.821344</td>\n",
       "      <td>0.959673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>var_rss12_q1</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>0.852796</td>\n",
       "      <td>1.059058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>var_rss12_q3</td>\n",
       "      <td>2.113157</td>\n",
       "      <td>1.942112</td>\n",
       "      <td>2.345517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>avg_rss13_min</td>\n",
       "      <td>2.939616</td>\n",
       "      <td>2.788000</td>\n",
       "      <td>3.137358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>avg_rss13_max</td>\n",
       "      <td>4.847358</td>\n",
       "      <td>4.248145</td>\n",
       "      <td>5.553795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>avg_rss13_mean</td>\n",
       "      <td>3.985546</td>\n",
       "      <td>3.512565</td>\n",
       "      <td>4.572220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>avg_rss13_median</td>\n",
       "      <td>4.013397</td>\n",
       "      <td>3.513560</td>\n",
       "      <td>4.621563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>avg_rss13_std</td>\n",
       "      <td>0.941300</td>\n",
       "      <td>0.764199</td>\n",
       "      <td>1.126258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>avg_rss13_q1</td>\n",
       "      <td>4.196608</td>\n",
       "      <td>3.735638</td>\n",
       "      <td>4.789360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>avg_rss13_q3</td>\n",
       "      <td>4.147858</td>\n",
       "      <td>3.638391</td>\n",
       "      <td>4.784040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>var_rss13_min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>var_rss13_max</td>\n",
       "      <td>2.171183</td>\n",
       "      <td>1.998991</td>\n",
       "      <td>2.376574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>var_rss13_mean</td>\n",
       "      <td>1.159427</td>\n",
       "      <td>1.103160</td>\n",
       "      <td>1.249785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>var_rss13_median</td>\n",
       "      <td>1.139058</td>\n",
       "      <td>1.083154</td>\n",
       "      <td>1.230190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>var_rss13_std</td>\n",
       "      <td>0.455589</td>\n",
       "      <td>0.427770</td>\n",
       "      <td>0.492273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>var_rss13_q1</td>\n",
       "      <td>0.838813</td>\n",
       "      <td>0.792187</td>\n",
       "      <td>0.907418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>var_rss13_q3</td>\n",
       "      <td>1.543658</td>\n",
       "      <td>1.469203</td>\n",
       "      <td>1.665928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>avg_rss23_min</td>\n",
       "      <td>6.089107</td>\n",
       "      <td>4.732536</td>\n",
       "      <td>7.807292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>avg_rss23_max</td>\n",
       "      <td>5.708524</td>\n",
       "      <td>4.880927</td>\n",
       "      <td>6.699349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>avg_rss23_mean</td>\n",
       "      <td>5.643253</td>\n",
       "      <td>4.590120</td>\n",
       "      <td>6.873196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>avg_rss23_median</td>\n",
       "      <td>5.780655</td>\n",
       "      <td>4.703295</td>\n",
       "      <td>7.046618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>avg_rss23_std</td>\n",
       "      <td>1.019033</td>\n",
       "      <td>0.827345</td>\n",
       "      <td>1.227605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>avg_rss23_q1</td>\n",
       "      <td>6.061727</td>\n",
       "      <td>4.954209</td>\n",
       "      <td>7.345726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>avg_rss23_q3</td>\n",
       "      <td>5.500200</td>\n",
       "      <td>4.494905</td>\n",
       "      <td>6.683400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>var_rss23_min</td>\n",
       "      <td>0.045577</td>\n",
       "      <td>0.013125</td>\n",
       "      <td>0.091154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>var_rss23_max</td>\n",
       "      <td>2.504568</td>\n",
       "      <td>2.258581</td>\n",
       "      <td>2.765657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>var_rss23_mean</td>\n",
       "      <td>1.148191</td>\n",
       "      <td>1.088982</td>\n",
       "      <td>1.241290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>var_rss23_median</td>\n",
       "      <td>1.080284</td>\n",
       "      <td>1.019601</td>\n",
       "      <td>1.170635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>var_rss23_std</td>\n",
       "      <td>0.514618</td>\n",
       "      <td>0.486999</td>\n",
       "      <td>0.553543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>var_rss23_q1</td>\n",
       "      <td>0.754261</td>\n",
       "      <td>0.704580</td>\n",
       "      <td>0.823960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>var_rss23_q3</td>\n",
       "      <td>1.514918</td>\n",
       "      <td>1.438727</td>\n",
       "      <td>1.633312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Feature       std  ci_lower   ci_upper\n",
       "0      avg_rss12_min  9.515445  8.316092  10.829000\n",
       "1      avg_rss12_max  4.369322  3.459442   5.431541\n",
       "2     avg_rss12_mean  5.305300  4.749321   5.919256\n",
       "3   avg_rss12_median  5.409056  4.854978   6.058866\n",
       "4      avg_rss12_std  1.762057  1.578340   1.958987\n",
       "5       avg_rss12_q1  6.118526  5.635953   6.688424\n",
       "6       avg_rss12_q3  5.109643  4.417823   5.912804\n",
       "7      var_rss12_min  0.000000  0.000000   0.000000\n",
       "8      var_rss12_max  5.033882  4.690841   5.468741\n",
       "9     var_rss12_mean  1.565200  1.436794   1.742884\n",
       "10  var_rss12_median  1.404197  1.273639   1.579537\n",
       "11     var_rss12_std  0.879066  0.821344   0.959673\n",
       "12      var_rss12_q1  0.940994  0.852796   1.059058\n",
       "13      var_rss12_q3  2.113157  1.942112   2.345517\n",
       "14     avg_rss13_min  2.939616  2.788000   3.137358\n",
       "15     avg_rss13_max  4.847358  4.248145   5.553795\n",
       "16    avg_rss13_mean  3.985546  3.512565   4.572220\n",
       "17  avg_rss13_median  4.013397  3.513560   4.621563\n",
       "18     avg_rss13_std  0.941300  0.764199   1.126258\n",
       "19      avg_rss13_q1  4.196608  3.735638   4.789360\n",
       "20      avg_rss13_q3  4.147858  3.638391   4.784040\n",
       "21     var_rss13_min  0.000000  0.000000   0.000000\n",
       "22     var_rss13_max  2.171183  1.998991   2.376574\n",
       "23    var_rss13_mean  1.159427  1.103160   1.249785\n",
       "24  var_rss13_median  1.139058  1.083154   1.230190\n",
       "25     var_rss13_std  0.455589  0.427770   0.492273\n",
       "26      var_rss13_q1  0.838813  0.792187   0.907418\n",
       "27      var_rss13_q3  1.543658  1.469203   1.665928\n",
       "28     avg_rss23_min  6.089107  4.732536   7.807292\n",
       "29     avg_rss23_max  5.708524  4.880927   6.699349\n",
       "30    avg_rss23_mean  5.643253  4.590120   6.873196\n",
       "31  avg_rss23_median  5.780655  4.703295   7.046618\n",
       "32     avg_rss23_std  1.019033  0.827345   1.227605\n",
       "33      avg_rss23_q1  6.061727  4.954209   7.345726\n",
       "34      avg_rss23_q3  5.500200  4.494905   6.683400\n",
       "35     var_rss23_min  0.045577  0.013125   0.091154\n",
       "36     var_rss23_max  2.504568  2.258581   2.765657\n",
       "37    var_rss23_mean  1.148191  1.088982   1.241290\n",
       "38  var_rss23_median  1.080284  1.019601   1.170635\n",
       "39     var_rss23_std  0.514618  0.486999   0.553543\n",
       "40      var_rss23_q1  0.754261  0.704580   0.823960\n",
       "41      var_rss23_q3  1.514918  1.438727   1.633312"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an empty DataFrame to store results\n",
    "results_df = pd.DataFrame(columns=['Feature', 'std', 'ci_lower', 'ci_upper'])\n",
    "\n",
    "# loop through columns and calculate std and confidence intervals\n",
    "for col in stats_df_noIndex.columns:\n",
    "    data = stats_df_noIndex[col].to_numpy()\n",
    "    std = np.std(data)\n",
    "    std_ci = bs.bootstrap(data, stat_func=bs_stats.std, alpha=0.1)\n",
    "    results_df = results_df.append({'Feature': col, 'std': std, \n",
    "                                    'ci_lower': std_ci.lower_bound, \n",
    "                                    'ci_upper': std_ci.upper_bound}, \n",
    "                                   ignore_index=True)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### iv. Select Features\n",
    "iv. Use your judgement to select the three most important time-domain features\n",
    "(one option may be min, mean, and max)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I suggest using the mean, standard deviation, and either the range (i.e., max-min) or the median. These features are crucial because they provide insight into the spread and skewness of the time-series data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ISLR 3.7.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. I collect a set of data (n = 100 observations) containing a single\n",
    "predictor and a quantitative response. I then fit a linear regression\n",
    "model to the data, as well as a separate cubic regression, i.e. Y =\n",
    "β0 + β1X + β2X2 + β3X3 + ϵ.\n",
    "\n",
    "\n",
    "(a) Suppose that the true relationship between X and Y is linear,\n",
    "i.e. Y = β0 + β1X + ϵ. Consider the training residual sum of\n",
    "squares (RSS) for the linear regression, and also the training\n",
    "RSS for the cubic regression. Would we expect one to be lower\n",
    "than the other, would we expect them to be the same, or is there\n",
    "not enough information to tell? Justify your answer.\n",
    "\n",
    "\n",
    "(b) Answer (a) using test rather than training RSS.\n",
    "\n",
    "\n",
    "\n",
    "(c) Suppose that the true relationship between X and Y is not linear,\n",
    "but we don’t know how far it is from linear. Consider the training\n",
    "RSS for the linear regression, and also the training RSS for the\n",
    "cubic regression. Would we expect one to be lower than the\n",
    "other, would we expect them to be the same, or is there not\n",
    "enough information to tell? Justify your answer.\n",
    "\n",
    "(d) Answer (c) using test rather than training RSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Linear Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the true relationship between X and Y is linear, then fitting a cubic regression model will likely result in overfitting. Due to the cubic regression's higher degree of flexibility that allows the cubic model to fit more closely to the data points, resulting in a tighter fit. As a result, the cubic regression model will likely have a lower training RSS than the linear regression model, but this does not necessarily mean that it will have a lower test RSS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Linear Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When evaluating a model's performance on a test set, it is likely that the residual sum of squares (RSS) for the cubic regression model will be higher than that of the linear regression model, assuming a linear relationship between the predictor and response variables. This is because the cubic model, with its higher degree of flexibility, may overfit to the training data, resulting in minimal bias reduction. Furthermore, the increased variance of the cubic model in a true linear relationship may offset any bias reduction gained, making the variance reduction provided by a linear model fit more significan\n",
    "\n",
    "\n",
    "In summary, overfitting leads to a low RSS on the training data and a high RSS on the validation or test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Not Linear Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cubic model is expected to exhibit a lower RSS due to its greater degree of flexibility, which enables it to incorporate more degrees of freedom than the linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Not Linear Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is difficult to determine which model would perform better since we lack information regarding the nature of the data and how non-linear the true relationship between X and Y is.\n",
    "\n",
    "If the true relationship is only slightly nonlinear, then the linear model may still provide a good fit and have a lower training RSS than the cubic model. But if the true relationship is highly nonlinear, then the cubic model may provide a better fit and have a lower training RSS than the linear model. Therefore, it is important to evaluate the performance of both models using cross-validation or other techniques to ensure that the model selected is the one that provides the best balance between simplicity and accuracy.\"\n",
    "\n",
    "In general, a simpler model like linear regression is preferred unless there is evidence that a more complex model like cubic regression is necessary to capture the underlying true relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Time Series Classification Part 1: Feature Creation/Extraction (HW3 Rerun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "294.435px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "3c20c2d94d2527936fe0f3a300eb11db30fed84423423838e2f93b74eb7aaebc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
